import { Controller, Sse, MessageEvent, Query } from '@nestjs/common';
import { Observable, interval } from 'rxjs';
import { mergeMap, take } from 'rxjs/operators';
import { ChatsService } from './chats/chats.service';

interface StreamChunk {
  type: 'start' | 'chunk' | 'end';
  content: string;
  messageId: string;
}

@Controller('api')
export class AppController {
  constructor(private readonly chatsService: ChatsService) {}

  private generateResponse(userMessage: string): string {
    const lowerMessage = userMessage.toLowerCase();

    if (lowerMessage.includes('ì•ˆë…•') || lowerMessage.includes('hello')) {
      return `ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š

ì €ëŠ” ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‘ë‹µí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!`;
    }

    if (lowerMessage.includes('ë‚ ì”¨')) {
      return `ì˜¤ëŠ˜ ë‚ ì”¨ì— ëŒ€í•´ ë¬¼ì–´ë³´ì…¨ë„¤ìš”.

ì‹¤ì œ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ë ¤ë©´ ì™¸ë¶€ APIì™€ ì—°ë™ì´ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬ëŠ” ë°ëª¨ ë²„ì „ì´ë¼ ì‹¤ì œ ë‚ ì”¨ ë°ì´í„°ëŠ” ì œê³µí•˜ì§€ ì•Šì§€ë§Œ, ë‚ ì”¨ APIë¥¼ ì—°ë™í•˜ë©´ ì‹¤ì‹œê°„ ë‚ ì”¨ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

ì˜ˆë¥¼ ë“¤ì–´:
- OpenWeatherMap API
- ê¸°ìƒì²­ API
ë“±ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.`;
    }

    if (lowerMessage.includes('ì½”ë“œ') || lowerMessage.includes('í”„ë¡œê·¸ë˜ë°')) {
      return `í”„ë¡œê·¸ë˜ë°ì— ê´€ì‹¬ì´ ìˆìœ¼ì‹œêµ°ìš”! ğŸ‘¨â€ğŸ’»

ì–´ë–¤ ì–¸ì–´ë‚˜ ê¸°ìˆ ì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?

ì €ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì£¼ì œë¡œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- JavaScript/TypeScript
- React, Vue, Angular
- Node.js, NestJS
- Python, Java, Go
- ì•Œê³ ë¦¬ì¦˜ê³¼ ìë£Œêµ¬ì¡°
- ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„

êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë” ìì„¸íˆ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤!`;
    }

    // ê¸°ë³¸ ì‘ë‹µ
    return `"${userMessage}"ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.

ì´ê²ƒì€ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°ëª¨ì…ë‹ˆë‹¤. ì‹¤ì œ AI ëª¨ë¸ì„ ì—°ë™í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **OpenAI GPT API**: GPT-3.5, GPT-4 ë“±
2. **Anthropic Claude API**: Claude 3 ëª¨ë¸ë“¤
3. **Google PaLM API**: Googleì˜ ëŒ€í™”í˜• AI
4. **ìì²´ AI ëª¨ë¸**: ì§ì ‘ í›ˆë ¨í•œ ëª¨ë¸

ê° ë¬¸ìê°€ í•˜ë‚˜ì”© ì „ì†¡ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì‹¤ì œ AI ì„œë¹„ìŠ¤ì™€ ë™ì¼í•œ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤!

ê¶ê¸ˆí•œ ì ì´ ë” ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”. ğŸ˜Š`;
  }

  @Sse('sse')
  sse(
    @Query('message') userMessage: string,
    @Query('conversationId') conversationId: number,
  ): Observable<MessageEvent> {
    const messageId = Date.now().toString();
    const fullResponse = this.generateResponse(userMessage || 'ì•ˆë…•í•˜ì„¸ìš”');

    const chunks = fullResponse.split('');
    const totalChunks = chunks.length;

    const typingSpeed = 25;

    // ğŸ”¥ ì—¬ê¸°ì„œ ì„œë²„ ì¸¡ ë²„í¼ ìƒì„±
    let buffer = '';

    return interval(typingSpeed).pipe(
      take(totalChunks + 2),
      mergeMap(async (index) => {
        let chunk: StreamChunk;

        if (index === 0) {
          chunk = {
            type: 'start',
            content: '',
            messageId,
          };
        } else if (index <= totalChunks) {
          const content = chunks[index - 1];
          buffer += content; // ğŸ”¥ chunk ëˆ„ì 

          chunk = {
            type: 'chunk',
            content,
            messageId,
          };
        } else {
          // ğŸ”¥ end ì‹œì  â†’ ì „ì²´ assistant ë©”ì‹œì§€ DB ì €ì¥
          await this.chatsService.createMessage(
            conversationId,
            'assistant',
            buffer,
          );

          chunk = {
            type: 'end',
            content: '',
            messageId,
          };
        }

        return { data: chunk } as MessageEvent;
      }),
    );
  }
}
